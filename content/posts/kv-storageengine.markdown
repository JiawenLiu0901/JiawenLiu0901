---
weight: 4
title: "KV分布式项目-存储引擎知识点整理总结"
date: 2023-03-20T21:57:40+08:00
lastmod: 2023-03-20T16:45:40+08:00
draft: false
author: "Jiawen Liu"
authorLink: "https://jiawenliu0901.github.io"
description: "哈希表、B+树、LSM树知识点整理总结"
tags: ["KV分布式项目"]
categories: ["KV分布式项目"]
lightgallery: true
---
# 哈希表

## 请解释哈希表(hash table)的基本原理和它是如何工作的

hashing：使用哈希方程将键转化成整数作为index，使用一个数组来储存每个键对应的值，并且用转化为整数的键来获取数组对应位置上的值。

compression：如果转化过的值大于数组的大小，则通过取余数的方式来进行压缩

collison哈希冲突：

## 哈希表与数组和链表相比有哪些优势？

1.  **快速的查找操作：**
    哈希表通过哈希函数将键映射到索引位置，使得查找操作平均时间复杂度为
    O(1)，即常数时间。相比之下，数组的查找操作需要线性搜索（O(n)
    时间），而链表需要遍历整个链表（O(n) 时间）。

2.  **动态大小：**
    哈希表可以根据需要动态调整大小，支持动态插入和删除操作。相比之下，数组在静态情况下需要预先分配固定大小的内存，而链表的大小可以动态调整，但在查找时需要遍历。

3.  **适合大数据集：**
    对于大数据集，哈希表可以通过合理设计哈希函数和解决冲突的方式来提供高效的性能。在这方面，数组和链表可能会因为线性搜索的复杂度而受到限制。

4.  **适合无序数据：**
    哈希表对于无序数据的查找和插入效率较高，因为它不要求元素的顺序。相比之下，数组和链表在无序数据的查找时需要遍历。

哈希表也有一些限制和注意事项：

1.  **冲突处理：**
    哈希表可能会发生冲突，即两个不同的键映射到相同的位置。冲突的解决策略需要谨慎选择，以确保维护良好的性能。

2.  **额外空间开销：**
    哈希表可能会占用较多的额外内存，尤其在负载因子较高时。相比之下，数组和链表通常对内存的利用更为高效。

3.  **不适合有序数据：**
    哈希表的优势在于无序数据的快速查找，但对于有序数据，数组可能更为适合。

4.  **哈希函数选择：**
    哈希表的性能也取决于合适的哈希函数的选择。一个不好的哈希函数可能导致冲突增多，影响性能。

## 什么是哈希冲突，如何解决？

哈希冲突或多或少都会发生，当不同的键被对应到了相同的索引，哈希冲突发生，我们要试图用O(1)的时间复杂度解决哈希冲突。

解决哈希冲突的四种方式：

1.  seperate chaining

插入键：O(1)（如果重复的键允许），O(N/M)（如果重复的键不允许）

查找：O(N/M)，删除：O(N/M)

以下是开放型寻址方法：

2.  linear probing线性探测：检查i+1, i+2, i+3...

可能导致聚类（clustering），降低哈希表的搜索效率

3.  quadratic probing 二次探测：检查i+1^2, i+2^2, i+3^2...

改善线性探测导致的聚类问题

4.  double hashing：检查i+1\*t'(key), i+2\*t'(key), i+3\*t'(key)...

使哈希表分布更加均匀，进一步提升哈希表的搜索效率

**为什么双哈希需要哈希表的容量是一个质数？**

假设我们哈希表的容量为15，某个「关键字」经过双哈希函数后得到的数组下标为0，步长为5。那么这个探测过程是0,5,10,0,5,10，一直只会尝试这三个位置，永远找不到空白位置来存放，最终会导致崩溃。

如果我们哈希表的大小为13，某个「关键字」经过双哈希函数后得到的数组下标为0，步长为5。那么这个探测过程是0,5,10,2,7,12,4,9,1,6,11,3。会查找到哈希表中的每一个位置。

使用开放地址法，不管使用那种策略都会有各种问题，开放地址法不怎么使用，在开放地址法中使用较多的是双哈希策略。

如果在创建哈希表时，不知道未来存储的数据有多少，使用链表法要比开放地址法好，如果使用开放地址法，随着装载因子的变大，性能会直线下降。

## 请描述一种你熟悉的哈希函数，并解释其特点。

Division hashing除留余数法

\|h(t)\| mod M
理想情况下表的大小M应该为一个质数，非质数的哈希表大小会引起更多的哈希冲突

MAD (Multiply and Divide) method

\|a \* h(t)+b\| mod
M，其中a和b为质数，如果无法控制哈希表大小，可以使用这个方法

## 在设计哈希表时，如何选择合适的哈希函数(hash function)？

## 哈希表如何实现插入操作？

计算哈希值-\>压缩-\>探测index i位置上的情况（三种探测方式）

- empty：直接插入元素

- delete/full：进行探测是否键值已经在哈希表上出现过了，如果出现过不再进行插入，如果没出现过就要么插入之前删除的位置要么在探测的空位上插入

- hit不再进行插入

## 哈希表如何实现删除操作？

计算哈希值-\>压缩-\>探测index i位置上的情况（三种探测方式）

- empty：键值在哈希表中不存在

- delete/full：进行探测是否键值已经在哈希表上出现过了，如果出现过就进行删除，如果没出现过就不再进行删除

- hit直接删除

## 哈希表如何实现查找操作，其时间复杂度是多少？

计算哈希值-\>压缩-\>探测index i位置上的情况（三种探测方式）

- empty：直接插入元素

- delete/full：进行探测是否键值已经在哈希表上出现过了，如果出现过即返回一个指向键值对的迭代器，如果没出现过就查找失败

- hit查找成功

哈希表的查找操作的平均时间复杂度是
O(1)，即常数时间。这是因为哈希表通过哈希函数将键映射到索引位置，理想情况下，不考虑冲突的影响，可以直接在常数时间内找到目标值。然而，在考虑哈希冲突的情况下，查找操作的实际时间复杂度可能受到冲突处理策略的影响。在开放寻址法中，冲突可能导致线性或二次探测的过程，而在链地址法中，可能需要遍历链表。因此，实际的查找操作时间复杂度可能受到冲突解决策略和哈希表的负载因子等因素的影响。

## 如何处理哈希表的扩容和缩容？(dynamic hashing)

扩容/缩容

1.  如果负载因子超过了0.5，将哈希表的大小扩大一倍，扩容并插入新元素的平摊成本为O(1)

2.  将旧哈希表的每个元素用新的哈希方程放到新的哈希表中

## 哈希表在哪些场景下不适用，为什么？

1.  **有序数据需求：**
    哈希表是为了快速的无序数据查找而设计的。如果应用需要对数据进行有序的访问或者需要支持范围查询，使用哈希表可能不是最佳选择。在这种情况下，树结构（例如二叉搜索树或平衡树）可能更适用。

2.  **内存限制：**
    哈希表可能在内存使用方面相对较高，特别是当负载因子较高时。在内存受限的环境下，可能需要考虑其他数据结构，例如压缩数据结构或者直接使用数组。

3.  **哈希函数冲突难以处理：**
    尽管哈希表通过哈希函数和冲突解决策略来处理冲突，但在某些情况下，冲突可能难以有效地处理。例如，如果哈希函数设计不当或者数据分布不均匀，可能导致冲突频繁发生，影响性能。

4.  **删除操作频繁：**
    哈希表中的删除操作可能涉及到标记删除或者移动元素，这可能导致性能下降。在执行大量删除操作的情况下，可能需要考虑其他数据结构，如跳表或平衡树。

5.  **实时性要求较高：**
    在实时系统中，哈希表的性能可能受到负载因子、哈希冲突等因素的影响，而导致性能不稳定。在对实时性有较高要求的场景下，可能需要考虑使用其他更为稳定的数据结构。

## 哈希表与二叉搜索树（BST）相比有哪些异同？

查找效率：
哈希表和二叉搜索树都可以提供较快的查找效率。在理想情况下，哈希表的平均查找时间为
O(1)，而二叉搜索树的平均查找时间为 O(log n)。

数据存储： 两者都用于存储键值对或者是具有某种排序关系的数据。

不同点：

插入和删除效率：
在插入和删除操作上，哈希表通常具有更好的性能。在理想情况下，哈希表的插入和删除的时间复杂度也是
O(1)。而在最坏情况下，二叉搜索树的插入和删除可能需要 O(log n)
的时间，取决于树的平衡性。

有序性：
二叉搜索树具有天然的有序性，因为它满足左子树的节点值小于根节点，右子树的节点值大于根节点的条件。这使得二叉搜索树在某些场景下更适合需要有序数据的操作。相比之下，哈希表的存储是无序的，因为哈希函数通常无法保证顺序性。

内存占用：
一般情况下，哈希表可能占用更多的内存，因为它需要维护哈希表的结构和解决冲突的机制。相比之下，简单的二叉搜索树在某些情况下可能更节省空间。然而，如果考虑到哈希表的负载因子和冲突解决机制的合理设计，它在实际应用中通常也可以保持较低的内存占用。

冲突问题：
哈希表可能会发生冲突，需要合适的冲突解决策略，如开放寻址法或链地址法。而二叉搜索树不涉及冲突问题。

哈希函数选择：
哈希表的性能高度依赖于哈希函数的选择，不同的哈希函数可能导致不同的性能表现。二叉搜索树则不受哈希函数的影响。

## 哈希表如何解决动态规划中的状态压缩问题？

## 请描述一种基于哈希表的算法，用于解决某个具体问题。

two sum

## 在哈希表中，如何处理哈希值为null的情况？

## 哈希表与字典树（Trie）有哪些区别和联系？

## 如何评估哈希表的性能，有哪些指标？

1.  load factor负载因子

2.  表的大小：一个高效的哈希表应该可以基于数据的大小来动态规划自己的长度

- 负载因子loading
  factor：哈希表被装满的百分比。如果使用的是线性探测，负载因子最好不要超过一半避免搜索效率下降。如果使用的是二次探测，由于二次剩余，一个大小是M的哈希表的余数是有限的，因此如果用的是二次探测，一个负载因子大于0.5的哈希表是危险的，有可能造成无限冲突

## 哈希表在数据库索引中的应用是怎样的？

提供高效的数据访问能力O(1)

## 在分布式系统中，如何实现哈希表的一致性？

一致性哈希算法：我们需要一个不直接依赖于服务器数量的分配方案，以便在添加或删除服务器时，将需要重新定位的key的数量降至最低。于是一致性hash算法应运而生。

一致性hash算法本质上也是一种取模算法；不过，不同于按服务器数量取模，一致性hash是对固定值2^32取模。（IPv4地址是由32位2进制数组成，所以用2^32可以保证每个IP地址会有唯一的映射；）我们可以将这2^32个值抽象成一个圆环，圆环的正上方的点代表0，顺时针排列，以此类推：1、2、3…直到2^32-1，而这个由2的32次方个点组成的圆环统称为hash环；

## 哈希表如何支持并发访问和操作？

页面互斥锁：每个页面都有一个自己的读写互斥锁，用于保护整个页面的内容。线程在访问页面之前会获取读锁或写锁。这会减少并行性，因为潜在地只有一个线程可以同时访问页面，但对于单个线程访问页面中的多个插槽来说，速度会很快，因为它只需获取一个互斥锁。

插槽互斥锁：每个插槽都有一个自己的互斥锁。这会增加并行性，因为两个线程可以同时访问同一页面上的不同插槽。但这会增加访问表的存储和计算开销，因为线程必须为它们访问的每个插槽获取一个互斥锁，而每个插槽都必须存储互斥锁的数据。数据库管理系统可以使用单模式互斥锁（即自旋锁）来减少元数据和计算开销，以换取一些并行性的代价。

## 你能想到哪些实际应用中使用了哈希表的数据结构？

std::unordered_map, std::unordered_set

# B+ tree

## 请解释B+树的基本概念和特点。

1.  B+树中的所有数据均保存在叶子结点，且根结点和内部结点均只是充当控制查找记录的媒介，并不代表数据本身，所有的内部结点元素都同时存在于子结点中，是子节点元素中是最大（或最小）元素。根结点的最大元素
    97 是整颗
    B+树当中最大的元素，无论之后在叶子结点中插入或删除多少元素，始终要保证最大元素在根结点当中，这个讲插入和删除时还会看到。

2.  每一个叶子结点都有指向下一个叶子结点的
    指针，便捷之处就在于之后我们将看到的区间查找。

## B+树与B树的主要区别是什么？

<img src="media/image1.png" style="width:5.26042in;height:2.28427in"
alt="descript" />

B-Tree是满足下列条件的数据结构：

d为大于1的一个正整数，称为B-Tree的度。

h为一个正整数，称为B-Tree的高度。

每个非叶子节点由n-1个key和n个指针组成，其中d\<=n\<=2d。

每个叶子节点最少包含一个key和两个指针，最多包含2d-1个key和2d个指针，叶节点的指针均为null
。

所有叶节点具有相同的深度，等于树高h。

key和指针互相间隔，节点两端是指针。

一个节点中的key从左到右非递减排列。

所有节点组成树结构。

每个指针要么为null，要么指向另外一个节点。

如果某个指针在节点node最左边且不为null，则其指向节点的所有key小于v(key1)v(key1)，其中v(key1)v(key1)为node的第一个key的值。

如果某个指针在节点node最右边且不为null，则其指向节点的所有key大于v(keym)v(keym)，其中v(keym)v(keym)为node的最后一个key的值。

如果某个指针在节点node的左右相邻key分别是keyikeyi和keyi+1keyi+1且不为null，则其指向节点的所有key小于v(keyi+1)v(keyi+1)且大于v(keyi)v(keyi)。

<img src="media/image2.png" style="width:5.30564in;height:2.6623in"
alt="descript" />

B+树每个节点的指针上限为2d而不是2d+1。

B+树内节点不存储data，只存储key；叶子节点不存储指针。

由于并不是所有节点都具有相同的域，因此B+Tree中叶节点和内节点一般大小不同。

一般在数据库系统或文件系统中使用的B+Tree结构都在经典B+Tree的基础上进行了优化，增加了顺序访问指针，极大提高了区间查询效率。

## B+树为什么更适合用于数据库索引？

先从B-Tree分析，根据B-Tree的定义，可知检索一次最多需要访问h个节点。数据库系统的设计者巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入。为了达到这个目的，在实际实现B-Tree还需要使用如下技巧：

每次新建节点时，直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了一个node只需一次I/O。

B-Tree中一次检索最多需要h-1次I/O（根节点常驻内存），渐进复杂度O(h) =
O(logdN)。一般实际应用中，出度d是非常大的数字，通常超过100，因此h非常小（通常不超过3）。

综上所述，用B-Tree作为索引结构效率是非常高的。

而红黑树这种结构，h明显要深的多。由于逻辑上很近的节点（父子）物理上可能很远，无法利用局部性，所以红黑树的I/O渐进复杂度也为O(h)，效率明显比B-Tree差很多。

上文还说过，B+Tree更适合外存索引，原因和内节点出度d有关。从上面分析可以看到，d越大索引的性能越好，而出度的上限取决于节点内key和data的大小：

dmax = floor(pagesize/(keysize+datasize+pointsize))

floor表示向下取整。由于B+Tree内节点去掉了data域，因此可以拥有更大的出度，拥有更好的性能。

## 在B+树中，叶子节点和非叶子节点各扮演什么角色？

B+树中的所有数据均保存在叶子结点，且根结点和内部结点均只是充当控制查找记录的媒介，并不代表数据本身，所有的内部结点元素都同时存在于子结点中，是子节点元素中是最大（或最小）元素。

## B+树的阶（order）是如何定义的，它对树的结构有何影响？

阶（order）通常指的是树的度（degree）。树的度定义了内部节点中最多可以存储的子节点数量，从而影响了整棵树的结构和性能。

内部节点： 每个内部节点最多可以包含order−1 个关键字和 order
个子节点。这意味着内部节点的子节点数量最多是 order。

叶子节点： 所有关键字都存储在叶子节点中，每个叶子节点最多可以包含
order−1 个关键字。

对于 B+ 树，通常会有一个最小度（通常称为 tt）的限制，要求
t≥2t≥2。这是为了确保树的结构和性能满足一些基本的要求。

影响 B+ 树结构和性能的因素包括：

树的高度：
较大的阶数通常会导致树的高度减小，因为每个节点可以存储更多的关键字，减少了树的层次，从而提高了查找效率。

节点的大小：
较大的阶数会导致节点变大，这对于内存或磁盘的访问可能会更有效率，因为一个节点可以存储更多的数据。

插入和删除的开销：
阶数的选择会影响插入和删除操作的开销。较小的阶数可能导致更频繁的节点分裂和合并操作，而较大的阶数则可能导致更大的节点重组开销。

磁盘页的利用率：
较大的阶数可能导致节点过大，而无法充分利用磁盘页的大小，可能会浪费存储空间。

## 如何向B+树中插入一个新的键值对？

1.  若被插入关键字所在的结点，其含有关键字数目小于阶数 M，则直接插入；

2.  若被插入关键字所在的结点，其含有关键字数目等于阶数
    M，则需要将该结点分裂为两个结点，一个结点包含 ⌊M/2⌋ ，另一个结点包含
    ⌈M/2⌉
    。同时，将⌈M/2⌉的关键字上移至其双亲结点。假设其双亲结点中包含的关键字个数小于
    M，则插入操作完成。

3.  在第 2 情况中，如果上移操作导致其双亲结点中关键字个数大于
    M，则应继续分裂其双亲结点。

4.  若插入的关键字比当前结点中的最大值还大，破坏了B+树中从根结点到当前结点的所有索引值，此时需要及时修正后，再做其他操作。

## 从B+树中删除一个键值对的过程是怎样的？

1.  找到存储有该关键字所在的结点时，由于该结点中关键字个数大于⌈M/2⌉，做删除操作不会破坏
    B+树，则可以直接删除。

2.  当删除某结点中最大或者最小的关键字，就会涉及到更改其双亲结点一直到根结点中所有索引值的更改。

3.  当删除该关键字，导致当前结点中关键字个数小于
    ⌈M/2⌉，若其兄弟结点中含有多余的关键字，可以从兄弟结点中借关键字完成删除操作。

4.  第 3
    种情况中，如果其兄弟结点没有多余的关键字，则需要同其兄弟结点进行合并。

<!-- -->

5.  当进行合并时，可能会产生因合并使其双亲结点破坏
    B+树的结构，需要依照以上规律处理其双亲结点。

## B+树如何进行分裂和合并操作？

分裂：若被插入关键字所在的结点，其含有关键字数目等于阶数
M，则需要将该结点分裂为两个结点，一个结点包含 ⌊M/2⌋ ，另一个结点包含
⌈M/2⌉
。同时，将⌈M/2⌉的关键字上移至其双亲结点。假设其双亲结点中包含的关键字个数小于
M，则插入操作完成。如果上移操作导致其双亲结点中关键字个数大于
M，则应继续分裂其双亲结点。

合并：一种是向兄弟结点去借，另外一种是同兄弟结点合并（情况 3、4 和 5）。

## B+树的查找操作是如何进行的，其时间复杂度是多少？

O(logn)

1.  B+树中的所有数据均保存在叶子结点，且根结点和内部结点均只是充当控制查找记录的媒介，并不代表数据本身，所有的内部结点元素都同时存在于子结点中，是子节点元素中是最大（或最小）元素。

2.  每一个叶子结点都有指向下一个叶子结点的指针，便捷之处就在于之后我们将看到的区间查找。

3.  对于 B+树中单个元素的查找而言，每一个元素都有相同的磁盘
    I/O操作次数，即使查询的元素出现在根结点中，但那只是一个充当控制查找记录的媒介，并不是数据本身，数据真正存在于叶子结点当中，所以
    B+树中查找任何一个元素都要从根结点一直走到叶子结点才可以。

4.  不再需要中序遍历，而是相当于单链表的遍历，B+树进行区间查找时更加简便实用。

## B+树中的节点分裂和合并操作如何影响树的高度？

在 B+
树中，节点分裂和合并操作对树的高度有着直接的影响。这两种操作通常是为了维护
B+ 树的平衡性以及满足定义中的阶数要求。

**节点分裂操作：**
当一个节点达到了其定义的最大关键字数量时，该节点会发生分裂。分裂操作会导致一个新的节点被创建，并将原节点的一部分关键字和子节点移动到新节点中。分裂操作可能会导致父节点的关键字数量增加，因为新节点的一个关键字会被提升到父节点。

**节点合并操作：**
当一个节点的关键字数量变得太少（小于定义的最小关键字数量）时，该节点可能会与其相邻的兄弟节点进行合并。合并操作会导致一个节点消失，并将其关键字合并到另一个节点中。这可能会导致父节点的关键字数量减少，因为一个关键字被从父节点中删除。

这两种操作的影响在于它们如何改变树的结构，从而影响树的高度：

- **节点分裂：**
  分裂操作增加了树的高度，因为一个新的节点被引入到树中。分裂可能会导致沿着树的高度发生变化，直到根节点。

<!-- -->

- **节点合并：**
  合并操作可能会减少树的高度，因为合并节点会消除一个层级。合并可能会导致高度的变化一直传播到树的根节点。

总的来说，B+
树通过这些操作来保持树的平衡，并确保树的高度在合理范围内，以维持高效的检索和插入性能。节点的分裂和合并使得
B+ 树可以适应动态数据集的变化。

## 

## B+树如何支持范围查询？

如图，查询key为从18到49的所有数据记录，当找到18后，只需顺着节点和指针顺序遍历就可以一次性访问到所有数据节点，极大提到了区间查询效率。<img src="media/image3.png" style="width:6.29931in;height:2.27802in"
alt="descript" />

## B+树中如何高效地实现顺序访问？

使用指针可以遍历所有的叶子结点，就和单链表一样，从而实现对磁盘上记录的有序访问。

## B+树在磁盘存储中的优势是什么？

减少树的高度： 阶数 d决定了每个节点可以包含的关键字数量。当 d
较大时，每个节点能够存储更多的关键字，从而减少了树的高度。树的高度与检索、插入和删除的性能直接相关，较低的树高意味着更快的操作。

提高局部性：
大的阶数意味着每个节点能够存储更多的关键字和子节点，从而在一个节点内部形成更好的局部性。在访问某个节点时，较大的阶数使得更多的相关数据可以一次性加载到内存中，提高了缓存的命中率。

降低树的宽度：
较大的阶数导致每一层的节点数量减少，从而降低了整棵树的宽度。较小的树宽度有助于减少磁盘或内存访问的次数，提高了检索性能。

降低树的维护开销：
在插入和删除操作时，较大的阶数通常意味着需要更新的节点数量较少。这降低了维护整棵树的开销，使得插入和删除等操作更为高效

B+树节点不保存数据，只保存key和指针，B+Tree更适合外存索引，原因和内节点出度d有关。从上面分析可以看到，d越大索引的性能越好，而出度的上限取决于节点内key和data的大小：

dmax

= floor(pagesize/(keysize+datasize+pointsize))

floor表示向下取整。由于B+Tree内节点去掉了data域，因此可以拥有更大的出度，拥有更好的性能。

## B+树如何处理磁盘I/O操作以提高性能？

顺序访问： B+
树节点的存储通常是顺序的，这意味着在磁盘上相邻的数据也是相邻的。这有助于提高磁盘
I/O 的性能，因为可以通过一次读取或写入操作获取或更新多个相邻的数据。

节点的完整性： B+
树的节点通常被设计为占用一个磁盘页（或多个连续的磁盘页），这有助于减少磁盘
I/O 操作。节点的完整性意味着一次 I/O
操作可以加载或写入一个完整的节点，而不仅仅是一个键值对。

缓存管理： B+
树通常会利用内存中的缓存来存储最近访问的节点，以减少对磁盘的访问。缓存可以存储磁盘上的部分树结构，以便在需要时可以直接从内存中获取。

预读取和预写入： B+
树可以使用预读取和预写入策略，通过预先加载或写入可能在不久的将来需要的数据，以降低磁盘
I/O 操作的延迟。

## B+树与哈希表在性能上有何异同？

如果需要支持范围查询、有序性要求高、适应动态数据集的变化，可以选择 B+
树。

如果主要进行查找操作，对于无序的键集合，且对内存占用比较敏感，可以选择哈希表。

## 在哪些场景下，B+树可能不是最优的索引结构，为什么？

1.  **高并发的写入操作：** 在高并发的写入操作场景下，B+
    树的节点分裂和合并操作可能会频繁发生，导致磁盘 I/O
    操作增多。这可能会影响写入性能。一些基于内存的数据结构，如跳表（Skip
    List）或 LSM 树（Log-Structured Merge
    Tree），在写入密集型场景下可能更为适用。

2.  **内存受限的情况：**
    如果数据集可以完全存放在内存中，而且查询操作频繁，那么一些基于内存的索引结构，如哈希表或跳表，可能更加适用。这是因为内存中的数据结构通常更简单且对于查找操作更为高效。

3.  **特定查询需求：**
    如果应用中的查询需求主要是等值查询，而不涉及范围查询或排序操作，可能使用哈希表等结构更为合适。哈希表在等值查询时具有
    O(1) 的平均时间复杂度。

4.  **实时性要求高：**
    在一些对实时性要求极高的应用场景下，例如实时监控系统，基于时间戳的索引结构（如
    LSM 树）可能更适合，因为它们能够更快地处理新的数据。

5.  **数据分布不均匀：**
    如果数据分布非常不均匀，导致哈希冲突较多，可能需要使用更适合处理哈希冲突的数据结构，而不是
    B+ 树。

## B+树如何支持并发访问和操作？

为了同一时刻只允许一个任务访问资源，需要用互斥锁对资源进行保护。互斥锁是一种简单的加锁的方法来控制对共享资源的访问，互斥锁只有两种状态,即上锁(
lock )和解锁( unlock )。

互斥锁特性：

原子性：互斥锁是一个原子操作，操作系统保证如果一个线程锁定了一个互斥锁，那么其他线程在同一时间不会成功锁定这个互斥锁

唯一性：如果一个线程锁定了一个互斥锁，在它解除锁之前，其他线程不可以锁定这个互斥锁

非忙等待：如果一个线程已经锁定了一个互斥锁，第二个线程又试图去锁定这个互斥锁，则第二个线程将被挂起且不占用任何CPU资源，直到第一个线程解除对这个互斥锁的锁定为止，第二个线程则被唤醒并继续执行，同时锁定这个互斥锁

互斥锁耦合（latch coupling）

basic idea:

1.  给父节点加锁

2.  给孩子节点加锁

3.  如果孩子节点是安全的（插入操作时节点不是满的，删除操作时节点比半满要多），给父节点解锁

## B+树中的索引键是如何排序的，这对性能有何影响？

自动按照升序大小排序，而且在叶子节点上保存了整个键值的有序列表。

B+
树的有序性对于支持范围查询、范围删除等操作是非常有利的。然而，有序性的维护可能会引入额外的开销，特别是在频繁的插入和删除操作时。

## 你能想到哪些实际应用中使用了B+树作为索引结构？

数据库管理系统，文件系统

## 在设计B+树索引时，需要考虑哪些因素以优化性能？

查找过程中磁盘I/O操作次数的渐进复杂度

# LSM tree 

## 请简要描述RocksDB是什么以及其主要用途。

基于日志结构（LSM
tree）存储引擎是为了解决**写多读少**的**特定场景**而提出的解决方案。

- 特定场景：日志系统、推荐系统、海量数据存储、数据分析

- 大量写：数据大量写入，用于做统计、分析；数据大量写入，用于线上检索、模型训练

- 少量读：少量读是和该系统的写入量相对衡量的，大部分场景对于读的实施性能要求相对低

## RocksDB中的“SSTables”是什么，它们在数据存储中扮演什么角色？

虽然leveldb采用了先写内存的方式来提高写入效率，但是内存中数据不可能无限增长，且日志中记录的写入操作过多，会导致异常发生时，恢复时间过长。因此内存中的数据达到一定容量，就需要将数据持久化到磁盘中。除了某些元数据文件，leveldb的数据主要都是通过sstable来进行存储。

虽然在内存中，所有的数据都是按序排列的，但是当多个memetable数据持久化到磁盘后，对应的不同的sstable之间是存在交集的，在读操作时，需要对所有的sstable文件进行遍历，严重影响了读取效率。因此leveldb后台会“定期“整合这些sstable文件，该过程也称为compaction。随着compaction的进行，sstable文件在逻辑上被分成若干层，由内存数据直接dump出来的文件称为level
0层文件，后期整合而成的文件为level i
层文件，这也是leveldb这个名字的由来。RocksDB如何实现数据的持久化存储？

## 在RocksDB中，如何处理数据的并发读写操作？

1.  多版本并发控制MVCC

2.  写前日志WAL

3.  compaction

4.  column families

5.  锁和\*原子操作

**\***"原子性"（Atomicity）是指一系列相关操作要么全部成功完成，要么全部失败，不会出现部分成功和部分失败的情况。原子性是事务（Transaction）的一个关键特性，确保事务在执行过程中的一系列操作要么全部生效，要么全部回滚。

## RocksDB中的Write-Ahead Logging（WAL）机制。

RocksDB中的每个更新操作都会写到两个地方：1）一个内存数据结构，名为memtable(后面会被刷盘到SST文件)
2）写到磁盘上的WAL日志。在出现崩溃的时候，WAL日志可以用于完整的恢复memtable中的数据，以保证数据库能恢复到原来的状态。在默认配置的情况下，RocksDB通过在每次写操作后对WAL调用fflush来保证一致性。

总的来说一个WAL文件会在以下时机被创建

1\. DB打开的时候

2\. 一个列族落盘数据的时候

## RocksDB中的内存表（MemTable）是什么，它如何影响写入性能？

memtable就是一个在内存中进行数据组织与维护的结构。memtable中，所有的数据按用户定义的排序方法排序之后按序存储，等到其存储内容的容量达到阈值时（默认为4MB），便将其转换成一个不可修改的memtable，与此同时创建一个新的memtable，供用户继续进行读写操作。memtable底层使用了一种跳表数据结构，这种数据结构效率可以比拟二叉查找树，绝大多数操作的时间复杂度为O(log
n)。

memtable的容量到达阈值时，便会转换成一个不可修改的memtable，也称为immutable
memtable。这两者的结构定义完全一样，区别只是immutable
memtable是只读的。当一个immutable
memtable被创建时，leveldb的后台压缩进程便会将利用其中的内容，创建一个sstable，持久化到磁盘文件中。

## RocksDB如何管理不同级别的SSTables以及它们之间的数据合并？

1.  主要依靠LSM
    tree这个结构。这个架构优化了磁盘写入操作，同时通过合理管理和合并
    SSTables 来保证读取操作的效率。

level
0：每个sstable之间可能会有重合，在0层中，文件编号大的sstable优先查找。理由是文件编号较大的sstable中存储的总是最新的数据。

level
none-zero：非0层文件，一层中所有文件之间的key不重合，因此leveldb可以借助sstable的元数据（一个文件中最小与最大的key值）进行快速定位，每一层只需要查找一个sstable文件的内容。

2.  Compaction

minor compaction：当文件从memTable转化到SSTable上的时候，主要发生在L0

major compaction：随着时间的推移，Rocks
DB会将较低层的SSTable进行合并，并将合并后的table放入更高层级

3.  层级大小和文件数量管理

每个层级可以存储的数据量是有限制的，这个限制是通过配置参数控制的。当一个层级的数据量超过了配置的限制，RocksDB
会触发 Compaction 过程，将数据合并到更高的层级。

层级之间的大小通常呈指数增长，即每个层级可以容纳的数据量比前一个层级大很多。这样设计是为了减少高层级的合并频率，从而降低对系统性能的影响。

4.  SSTables选择和合并策略

RocksDB 有多种 Compaction 策略，如大小压实（Size-Tiered
Compaction）和级别压实（Level
Compaction）。这些策略根据不同的使用场景和性能需求来选择。

在执行 Compaction 时，RocksDB 会根据键的范围选择需要合并的
SSTables，确保数据在合并过程中保持有序。

## 如何优化RocksDB的读性能？

<u>data block结构</u>

<img src="media/image4.png" style="width:3.54219in;height:4.71509in"
alt="descript" />

leveldb设计Restart point的目的是在读取sstable内容时，加速查找的过程。

由于每个Restart
point存储的都是完整的key值，因此在sstable中进行数据查找时，可以首先利用restart
point点的数据进行键值比较，以便于快速定位目标数据所在的区域；

当确定目标数据所在区域时，再依次对区间内所有数据项逐项比较key值，进行细粒度地查找；

该思想有点类似于跳表中利用高层数据迅速定位，底层数据详细查找的理念，降低查找的复杂度。

<u>filter block结构</u>

为了加快sstable中数据查询的效率，在直接查询datablock中的内容之前，leveldb首先根据filter
block中的过滤数据判断指定的datablock中是否有需要查询的数据，若判断不存在，则无需对这个datablock进行数据查找。

<img src="media/image5.png" style="width:6.29931in;height:4.80505in"
alt="descript" />

<u>缓存</u>

sstable文件句柄及其元数据；

data block中的数据；

Leveldb中使用了一种基于LRUCache的缓存机制，用于缓存：

已打开的sstable文件对象和相关元数据；

sstable中的dataBlock的内容；

使得在发生读取热数据时，尽量在cache中命中，避免IO读取。

<img src="media/image6.png" style="width:5.15286in;height:2.75566in"
alt="descript" />

故通过这个步骤的优化，可以直接确定目标数据项落在哪个data
block的范围区间内。

<u>查找data block</u>

<img src="media/image7.png" style="width:5.13818in;height:3.35694in"
alt="descript" />

## 在RocksDB中，如何处理数据删除和更新操作？

在 RocksDB
中，数据的删除和更新操作都是通过写入特殊类型的记录来实现的，这与其底层的日志结构合并树（Log-Structured
Merge-Tree，简称
LSM-Tree）的工作原理紧密相关。以下是处理这些操作的基本机制：

###  删除操作

RocksDB 处理删除操作通常使用两种方法：标记删除（Soft
Delete）和真实删除（Hard Delete）

1\. **标记删除（Soft Delete）**：

- RocksDB
  使用“墓碑”（tombstone）标记来实现软删除。当要删除一个键时，RocksDB
  写入一个带有删除标记的记录，而不是立即从物理存储中移除该键值对。

<!-- -->

- 在后续的合并（Compaction）过程中，带有墓碑标记的键和旧的键值对会被物理删除，释放空间。

<!-- -->

- 这种方法的优点是删除操作快速，不需要即时重写或移动大量数据，但缺点是删除操作不会立即回收空间，直到下一次合并发生。

2\. **真实删除（Hard Delete）**：

- 真实删除意味着从数据库中完全移除键值对的记录，通常在合并过程中完成。

<!-- -->

- 真实删除是自动进行的，当合并过程遇到墓碑记录时，它会移除所有相关的键值对。

###  更新操作

在 RocksDB 中，更新操作本质上是一次写入操作，遵循以下步骤：

1\. **写入新值**：当需要更新一个键的值时，RocksDB
简单地将新的键值对作为一个新记录写入到 MemTable
中。如果键已经存在，新的写入操作会覆盖旧的值。

2\. **合并和压缩**：随着时间的推移，同一个键可能会有多个版本分布在不同的
SSTables 中。在合并过程中，根据合并策略，RocksDB
会保留最新的值（考虑到时间戳或序列号），并且可能删除旧的值，以优化读性能和空间使用。

###  性能和空间考虑

- **合并策略**：RocksDB
  的合并过程是处理删除和更新操作，优化性能和空间使用的关键。通过配置合并策略，可以控制数据如何被合并和压缩，以平衡读写性能和空间回收。

<!-- -->

- **写放大**：由于 LSM-Tree
  的特性，删除和更新操作可能导致\*写放大，因为这些操作引发的数据重写和合并过程会写入更多数据。适当配置
  RocksDB 的合并和压缩策略可以帮助减少写放大。

通过理解和合理配置 RocksDB
的这些机制，可以有效地管理数据库中的删除和更新操作，优化数据库的性能和空间使用。

## 请描述RocksDB中的压缩(compaction)和去重功能是如何工作的。

在RocksDB中使用SST文件分层管理持久化的数据，即level 0到level
N，每层包含0个或多个sst文件，当满足某种规则时，通过Compaction操作将level
x中一个或多个文件与下层合并，默认的Compaction方式为Level
Compaction，以下也都是基于Level Compaction的流程。

除了level
0层，其他层的sst文件的key范围是不相交的，上面我们知道sst文件内部的key是有序的，因此level
1+的每一层的所有key在这一层整体来看也是有序的，在查找时整体也是二分查找。

那么level
1+的sst文件怎么保证没有交集呢，这就通过了Compaction这个操作来实现，Compaction主要流程(如下图)：在level
x中选中一个或多个sst文件与level
x+1中与这些文件有交集的sst文件做合并成新的sst文件，放入level
x+1中(如果没有交集则直接落到level
x+1层)，并删除这些选中的文件，Compaction完成后如果level
x+1也满足Compaction条件则继续向下做Compaction。这样就保证了每层Level不会过大，并且在Compaction的过程中能减少空间放大(有些对相同key多次操作都合并成一个了,例如对上下层都存有对key1做了put操作的记录，我们只需要留最新的put)。

## RocksDB支持哪些类型的数据压缩(compression)算法？

各种压缩SST 文件的压缩算法，例如Zlib、Bzip、Snappy、LZ4、 ZSTDNotFinal
或ZSTD

## RocksDB中的布隆过滤器（Bloom Filter）是什么，它如何帮助提高查询效率？

Bloom
Filter是一种空间效率很高的随机数据结构，它利用位数组很简洁地表示一个集合，并能判断一个元素是否属于这个集合。Bloom
Filter的这种高效是有一定代价的：在判断一个元素是否属于某个集合时，有可能会把不属于这个集合的元素误认为属于这个集合（false
positive）。因此，Bloom
Filter不适合那些“零错误”的应用场合。而在能容忍低错误率的应用场合下，Bloom
Filter通过极少的错误换取了存储空间的极大节省。

leveldb中利用布隆过滤器判断指定的key值是否存在于sstable中，若过滤器表示不存在，则该key一定不存在，由此加快了查找的效率。

## 请解释RocksDB中的快照功能以及它的应用场景。

API使用：

通过GetSnapshot API创建一个快照

通过设置ReadOptions::snapshot来读取快照的内容

当读取结束，调用ReleaseSnapshot释放相关资源

快照是数据库在某一时刻的状态，基于一个快照对数据进行读取，读取的内容不会因为后续数据的更改而改变。

每条数据项的编码格式：Batch<img src="media/image8.png" style="width:6.29931in;height:0.8447in"
alt="descript" />

在leveldb中，用户对同一个key的若干次修改（包括删除）是以维护多条数据项的方式进行存储的（直至进行compaction时才会合并成同一条记录），每条数据项都会被赋予一个序列号，代表这条数据项的新旧状态。一条数据项的序列号越大，表示其中代表的内容为最新值。

因此，每一个序列号，其实就代表着leveldb的一个状态。换句话说，每一个序列号都可以作为一个状态快照。

当用户主动或者被动地创建一个快照时，leveldb会以当前最新的序列号对其赋值。例如图中用户在序列号为98的时刻创建了一个快照，并且基于该快照读取key为“name”的数据时，即便此刻用户将"name"的值修改为"dog"，再删除，用户读取到的内容仍然是“cat”。

## RocksDB中的迭代器（Iterator）是什么，如何使用它进行范围查询？

迭代器被用户用于按顺序查询一个区间内的键值。

如果ReadOptions.snapshot被给出，那么迭代器会从一个快照里面返回数据。如果这是一个nullptr，迭代器隐式创建一个迭代器创建的时间节点的快照。该隐藏的快照会通过[固定资源](http://rocksdb.org.cn/doc/.html)来提供数据。隐式快照无法转换为显式快照

## 如何配置RocksDB以实现更好的写入吞吐量？

1.  调整MemTable的大小

2.  使用多个MemTable

3.  优化WAL

4.  SSTable compaction

5.  数据压缩

## RocksDB如何处理数据的版本控制和垃圾回收？

版本控制：

采用了MVCC来避免了读写冲突。

sstable文件是只读的，不可以被更改。每次compaction都只是对若干个sstable文件进行【\*多路合并】后创建新的文件，故不会影响在某个sstable文件读操作的正确性。

\*多路合并：它涉及到同时合并多个已排序的数据序列（或列表）成一个单一的、有序的结果序列。这种技术在多种场景下非常有用，如外部排序、数据库管理系统的索引构建和维护、以及归并排序算法的一部分。

sstable都是具有版本信息的，即每次compaction完成后，都会生成新版本的sstable，因此可以保障读写操作都可以针对于相应的版本文件进行，解决了读写冲突；

compaction生成的文件只有等合并完成后才会写入数据库元数据，在此期间对读操作来说是透明的，不会污染正常的读操作；

采用引用计数来控制删除行为。当compaction完成后试图去删除某个sstable文件，会根据该文件的引用计数作适当的删除延迟，即引用计数不为0时，需要等待至该文件的计数为0才真正进行删除；

垃圾回收：

随着时间的推移，由于数据的更新和删除操作，SSTables
中会累积大量的过时数据（即“垃圾”）。RocksDB
通过定期的压缩（Compaction）过程来清理这些无用的数据。

压缩（Compaction）：压缩是指将多个 SSTables 合并为一个新的 SSTable
的过程，在这个过程中，重复的键将被去重（保留最新的版本），而被删除标记的键将被完全移除。RocksDB
提供了多种压缩策略（如级别压缩、分层压缩），以适应不同的工作负载和性能需求。

空间回收：通过压缩过程，不再需要的旧数据版本和删除的数据被清理掉，释放了存储空间。

后台操作：为了不干扰前台的读写操作，压缩通常作为后台任务执行，并且可以根据系统的当前负载动态调整压缩的优先级和频率。

通过以上机制，RocksDB
能够有效地管理数据版本和进行垃圾回收，保证数据库的高性能和高空间利用率。需要注意的是，合理配置
RocksDB
的参数（如压缩策略、压缩触发条件等）对于优化性能和空间效率非常关键。

## 请描述RocksDB中的列族（Column Families）概念以及它们在数据组织中的作用。

在 RocksDB 中，列族（Column
Family）是一种重要的数据组织结构，它允许在同一个数据库实例中存储多个逻辑上分离的键值映射集合。每个列族可以被视为一个独立的键值表，具有自己的键值对、MemTable、SSTable，以及专属的配置参数，如压缩选项、布隆过滤器设置等。这种设计使得在同一个数据库中管理多种不同类型的数据变得更加灵活和高效。

###  列族的应用场景

- **存储不同类型的数据**：当需要在同一个数据库中存储不同类型的数据，且这些数据类型有不同的访问模式和存储需求时，列族非常有用。

<!-- -->

- **优化性能**：不同的列族可以有不同的配置，这意味着你可以针对特定类型的数据操作优化性能，例如，通过为频繁更新的数据选择不同的压缩策略。

<!-- -->

- **简化数据管理**：使用列族可以简化数据的管理和维护工作，因为每个列族可以独立进行垃圾收集、压缩等操作。

###  如何在 RocksDB 中使用列族

1\. **创建和打开列族**：

- 在打开一个 RocksDB
  数据库时，需要指定所有列族的名称。如果数据库是首次创建，通常只有一个默认的列族。

<!-- -->

- 要添加新的列族，可以使用 \`CreateColumnFamily\` 方法，并通过
  \`ColumnFamilyHandle\` 来对其进行操作。

2\. **进行数据操作**：

- 对于基本的键值操作（如
  \`Put\`、\`Get\`、\`Delete\`），需要指定相应的列族。这意味着同一个键可以在不同的列族中有不同的值。

<!-- -->

- 每个列族都可以独立配置，包括压缩选项、布隆过滤器等。

3\. **列族的管理**：

- 可以动态地添加和删除列族，这为动态调整数据库结构提供了灵活性。

<!-- -->

- 列族在删除时，与之相关的所有数据也会被删除。

- 在实际应用中，根据不同的数据存储需求和访问模式，合理设计和使用列族，可以显著提升
  RocksDB 的数据管理效率和性

## RocksDB支持哪些类型的API来进行数据操作？

1.  基本键存取API

2.  批处理API

3.  迭代器API

4.  Snapshot API

5.  列族相关API

## 如何监控RocksDB的性能和资源使用情况？

CPU 和内存分析器：如 gprof、Valgrind 或 perf
等工具，可以帮助识别热点函数和内存泄漏。

## 在实际应用中，如何选择合适的RocksDB配置参数以满足性能需求？
